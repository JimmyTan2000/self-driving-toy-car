{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch2trt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b55bd185ee13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch2trt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTRTModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch2trt'"
     ]
    }
   ],
   "source": [
    "from torch2trt import TRTModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jetbot/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch2trt (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for torch2trt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch2trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "# road following\n",
    "model_rf = torchvision.models.resnet18(pretrained=False)\n",
    "model_rf.fc = torch.nn.Linear(512, 2)\n",
    "\n",
    "# collision avoidance\n",
    "model_ca = torchvision.models.alexnet(pretrained=False)\n",
    "model_ca.classifier[6] = torch.nn.Linear(model_ca.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.load_state_dict(torch.load('best_steering_model_xy.pth')) # well trained road following model\n",
    "model_ca.load_state_dict(torch.load('best_model.pth')) # well trained collision avoidance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model_rf = model_rf.to(device)\n",
    "model_rf = model_rf.eval().half()\n",
    "\n",
    "model_ca = model_ca.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess_rf(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "# collision avoidance\n",
    "mean_ca = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev_ca = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean_ca, stdev_ca)\n",
    "\n",
    "def preprocess_ca(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224, fps=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19955dfdafdc4083b9e6edc2eaa1f87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_widget = ipywidgets.Image()\n",
    "\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d98370b06a4caaa23c4bdfe2e183b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='speed control', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa60608ebea41bbb8478d84afa75645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.04, description='steering gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9ab9ac7bbd40b58ebff35facfbf3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering kd', max=0.5, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d55ad38aa24a0cbd8af4af16d0f3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering bias', max=0.3, min=-0.3, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19955dfdafdc4083b9e6edc2eaa1f87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906a3770e809451cab3f61f5c9d2294d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, description='blocked', max=1.0), FloatSlider(value=0.8, description='blo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Road Following sliders\n",
    "speed_control_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed control')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.04, description='steering gain')\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "display(speed_control_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)\n",
    "\n",
    "#Collision Avoidance sliders\n",
    "blocked_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, orientation='horizontal', description='blocked')\n",
    "stopduration_slider= ipywidgets.IntSlider(min=1, max=1000, step=1, value=10, description='time for stop') \n",
    "blocked_threshold= ipywidgets.FloatSlider(min=0, max=1.0, step=0.01, value=0.8, description='blocked threshold')\n",
    "\n",
    "display(image_widget)\n",
    "\n",
    "display(ipywidgets.HBox([blocked_slider, blocked_threshold, stopduration_slider]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "count_stops = 0\n",
    "go_on = 1\n",
    "stop_time = 10 # The number of frames to remain stopped\n",
    "x = 0.0\n",
    "y = 0.0\n",
    "speed_value = speed_control_slider.value\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last, blocked_slider, robot, count_stops, stop_time, go_on, x, y, blocked_threshold\n",
    "    global speed_value, steer_gain, steer_dgain, steer_bias\n",
    "                \n",
    "    steer_gain = steering_gain_slider.value\n",
    "    steer_dgain = steering_dgain_slider.value\n",
    "    steer_bias = steering_bias_slider.value\n",
    "       \n",
    "    x = change['new'] \n",
    "    x = preprocess_ca(x)\n",
    "    y = model_ca(x)\n",
    "     \n",
    "    #Collision Avoidance model:\n",
    "    \n",
    "    prob_blocked = float(F.softmax(y, dim=1).flatten()[0])\n",
    "    \n",
    "    blocked_slider.value = prob_blocked    \n",
    "    stop_time=stopduration_slider.value\n",
    "    \n",
    "    if go_on == 1:    \n",
    "        if prob_blocked > blocked_threshold.value: # threshold should be above 0.5\n",
    "            count_stops += 1\n",
    "            go_on = 2\n",
    "        else:\n",
    "            #start of road following detection\n",
    "            go_on = 1\n",
    "            count_stops = 0\n",
    "            image = change['new']\n",
    "            xy = model_rf(preprocess_rf(image)).detach().float().cpu().numpy().flatten()        \n",
    "            x = xy[0]            \n",
    "            y = (0.5 - xy[1]) / 2.0\n",
    "            speed_value = speed_control_slider.value\n",
    "    else:\n",
    "        count_stops += 1\n",
    "        if count_stops < stop_time:\n",
    "            x = 0.0 #set x steering to zero\n",
    "            y = 0.0 #set y steering to zero\n",
    "            speed_value = 0 # set speed to zero (can set to turn as well)\n",
    "        else:\n",
    "            go_on = 1\n",
    "            count_stops = 0\n",
    "            \n",
    "    \n",
    "    angle = math.atan2(x, y)        \n",
    "    pid = angle * steer_gain + (angle - angle_last) * steer_dgain\n",
    "    steer_val = pid + steer_bias \n",
    "    angle_last = angle\n",
    "    robot.left_motor.value = max(min(speed_value + steer_val, 1.0), 0.0)\n",
    "    robot.right_motor.value = max(min(speed_value - steer_val, 1.0), 0.0) \n",
    "\n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/jetbot-0.4.0-py3.6.egg/jetbot/camera.py\", line 45, in _capture_frames\n",
      "    self.value = image\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py\", line 588, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py\", line 577, in set\n",
      "    obj._notify_trait(self.name, old_value, new_value)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py\", line 1210, in _notify_trait\n",
      "    type='change',\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py\", line 1215, in notify_change\n",
      "    return self._notify_observers(change)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py\", line 1252, in _notify_observers\n",
      "    c(event)\n",
      "  File \"<ipython-input-13-c8e5cdd8a8f8>\", line 55, in execute\n",
      "    angle = math.atan2(x, y)\n",
      "ValueError: only one element tensors can be converted to Python scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
